# -*- coding: utf-8 -*-
"""Fighting Overfittin.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eeN0ak_qev7tMzZ3YihqtNVfFwPYCV2Q

# ** Fighting Overfitting**


Tal Golan

# **Basic Code**
"""

from tensorflow import keras
from tensorflow.keras import layers
from keras import regularizers

# Loading the IMDB dataset
#******************************
from tensorflow.keras.datasets import imdb
(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)

train_data[0]

train_labels[0]

max([max(sequence) for sequence in train_data])

# Decoding reviews back to text
#******************************
word_index = imdb.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
decoded_review = " ".join([reverse_word_index.get(i - 3, "?") for i in train_data[0]])
decoded_review

#Preparing the data
#Encoding the integer sequences via multi-hot encoding
#*****************************************************
import numpy as np
def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        for j in sequence:
            results[i, j] = 1.
    return results
x_train = vectorize_sequences(train_data)
x_test = vectorize_sequences(test_data)

x_train[0]
y_train = np.asarray(train_labels).astype("float32")
y_test = np.asarray(test_labels).astype("float32")

"""# **Models:**

# **1. basic-No regularization:**
"""

basic_model = keras.Sequential()
basic_model.add(layers.Dense(16, activation="relu"))
basic_model.add(layers.Dense(16, activation="relu"))
basic_model.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
basic_model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_basic = basic_model.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_basic.history
history_dict.keys()

# Plotting the training and validation loss
#******************************************
import matplotlib.pyplot as plt
history_dict = history_basic.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, val_loss_values, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Plotting the training and validation accuracy
#**********************************************
plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training acc")
plt.plot(epochs, val_acc, "b", label="Validation acc")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""
# **2.Reduce the training set size by half (training + validation: 12,500):**"""

# Building your model
# Model definition
#******************************
model_new = keras.Sequential()
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Reducing the training and validation datasets to 12,500 samples total
x_val = x_train[:5000] # to be used for validation
partial_x_train = x_train[10000:17500]
y_val = y_train[:5000] # to be used for validation
partial_y_train = y_train[10000:17500]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_orig_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_mod_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (Reduce training set by half)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **3. Add L2 regularization - 0.02:**

**Lamda = 0.02**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.02), activation="relu"))
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.02), activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (L2 Regularization - Lamda = 0.02)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **3. Add L2 regularization - 0.005:**

**Lamda = 0.005**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.005), activation="relu"))
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.005), activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (L2 Regularization - Lamda = 0.005)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""Lamda = 0.005 was better for L2

# **4. Add L1 regularization - 0.02:**

**Lamda = 0.02**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.02), activation="relu"))
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.02), activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (L1 Regularization - Lamda = 0.02)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **4. Add L1 regularization - 0.005:**

**Lamda = 0.005**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.005), activation="relu"))
model_new.add(layers.Dense(16, kernel_regularizer=regularizers.l1(0.005), activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (L1 Regularization - Lamda = 0.005)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""Lamda = 0.005 was better for L1 Regularization

# **5. Add Dropout - 0.3:**

**Ratio = 0.3**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dropout(0.3))
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dropout(0.3))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (Dropout - 0.3)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **5. Add Dropout - 0.5:**

**Ratio = 0.5**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dropout(0.5))
model_new.add(layers.Dense(16, activation="relu"))
model_new.add(layers.Dropout(0.5))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (Dropout - 0.5)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""Dropout 50% was better

# **6. No regularization 8X4X1:**
"""

model_new = keras.Sequential()
model_new.add(layers.Dense(8, activation="relu"))
model_new.add(layers.Dense(4, activation="relu"))
model_new.add(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (No regularization 8X4X1)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **7. Add Dropout - 0.45 8X4X1:**

**Ratio = 0.45**
"""

model_new = keras.Sequential()
model_new(layers.Dense(8, activation="relu"))
model_new(layers.Dropout(0.45))
model_new(layers.Dense(4, activation="relu"))
model_new(layers.Dropout(0.45))
model_new(layers.Dense(1, activation="sigmoid"))

# Compiling the model
#******************************
model_new.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])

# Validating your approach
# Setting aside a validation set
#*******************************
x_val = x_train[:10000] # to be used for validation
partial_x_train = x_train[10000:]
y_val = y_train[:10000] # to be used for validation
partial_y_train = y_train[10000:]

# Training your model
#*******************************
history_new = model_new.fit(partial_x_train,
                    partial_y_train,
                    epochs=30,
                    batch_size=512,
                    validation_data=(x_val, y_val))

history_dict = history_new.history
history_dict.keys()

basic_final_val_acc = history_basic.history['val_accuracy'][-1]
new_final_val_acc = history_new.history['val_accuracy'][-1]

print(f"Basic Model Final Validation Accuracy: {basic_final_val_acc:.4f}")
print(f"New Model Final Validation Accuracy: {new_final_val_acc:.4f}")

# Find the best validation accuracy achieved by the original model
best_basic_val_acc = max(history_basic.history['val_accuracy'])

# Find the best validation accuracy achieved by the modified model
best_new_val_acc = max(history_new.history['val_accuracy'])

print(f"Best Validation Accuracy - Basic Model: {best_basic_val_acc:.4f}")
print(f"Best Validation Accuracy - New Model: {best_new_val_acc:.4f}")

# Plotting validation accuracy
plt.plot(history_basic.history["val_accuracy"], "bo", label="Basic Validation accuracy")
plt.plot(history_new.history["val_accuracy"], "r", label="New Validation accuracy (Dropout - 0.45 8X4X1)")
plt.title("Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

"""# **Chosen model:**"""

# Retraining a model from scratch
#********************************

best_model = keras.Sequential()
best_model.add(layers.Dense(16, activation="relu"))
best_model.add(layers.Dropout(0.5))
best_model.add(layers.Dense(16, activation="relu"))
best_model.add(layers.Dropout(0.5))
best_model.add(layers.Dense(1, activation="sigmoid"))

best_model.compile(optimizer="rmsprop",
              loss="binary_crossentropy",
              metrics=["accuracy"])
best_model.fit(x_train, y_train, epochs=4, batch_size=512)
results = best_model.evaluate(x_test, y_test)
results

# Using a trained model to generate predictions on new data
#**********************************************************
best_model.predict(x_test)